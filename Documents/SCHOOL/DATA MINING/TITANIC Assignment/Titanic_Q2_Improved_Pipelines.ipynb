{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f1e8e52",
   "metadata": {},
   "source": [
    "# Titanic Q2 — Improved Preprocessing & Cross‑Validated Model Comparison\n",
    "    \n",
    "**Course:** Data Mining  \n",
    "**Objective:** Improve upon the common Kaggle preprocessing by using leakage‑safe Pipelines, better feature engineering, and Stratified K‑Fold evaluation.  \n",
    "**Deliverable:** A table of mean CV accuracies (± std) for nine classifiers, with reproducible code.\n",
    "    \n",
    "### What this notebook does\n",
    "1. Loads the Titanic training data (`train.csv`) and (optionally) test data (`test.csv`).\n",
    "2. Builds a **leakage‑safe preprocessing pipeline** using scikit‑learn:\n",
    "   - Robust feature engineering (Deck, Title, FamilySize, Ticket group size, interactions).\n",
    "   - Rare-category grouping inside CV folds.\n",
    "   - Proper imputers per data type, and one‑hot encoding with `handle_unknown=\"ignore\"`.\n",
    "   - Scaling only where it helps (linear, SVM, KNN).\n",
    "3. Evaluates nine classifiers via **StratifiedKFold** with fixed random seed, reports **mean ± std accuracy**, and saves results to CSV.\n",
    "    \n",
    "> **Important:** Place `train.csv` (and optionally `test.csv`) in the same folder as this notebook. These are the standard Kaggle Titanic files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389c4a86",
   "metadata": {},
   "source": [
    "## 0) Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88f52342",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, Perceptron\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5291298",
   "metadata": {},
   "source": [
    "## 1) Load Data\n",
    "    \n",
    "Edit the `DATA_DIR` if your CSVs are somewhere else.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3aace3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DATA_DIR = '.'  # change if needed\n",
    "TRAIN_PATH = os.path.join(DATA_DIR, 'train.csv')\n",
    "TEST_PATH  = os.path.join(DATA_DIR, 'test.csv')\n",
    "\n",
    "assert os.path.exists(TRAIN_PATH), f\"train.csv not found at {TRAIN_PATH}. Please add it and re-run.\"\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH) if os.path.exists(TEST_PATH) else None\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ce45d",
   "metadata": {},
   "source": [
    "## 2) Improved Feature Engineering (leakage‑safe via a custom transformer)\n",
    "We avoid computing any statistics on the full dataset outside CV. All logic runs **inside** the Pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09cb7f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FeatureBuilder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Reproducible, leakage‑safe feature engineering for Titanic.\n",
    "    \n",
    "    - Extracts Title from Name and groups rare titles later in the pipeline\n",
    "    - Deck from Cabin initial; 'U' if unknown\n",
    "    - FamilySize, IsAlone\n",
    "    - TicketPrefix and GroupSizeByTicket\n",
    "    - Interactions: Age*Pclass (later after imputation), Sex x Pclass (via one-hot)\n",
    "    - FarePerPerson = Fare / FamilySize (handles division carefully)\n",
    "    - Adds binned copies (AgeBin/FareBin) as categorical features (optional)\n",
    "    \"\"\"\n",
    "    def __init__(self, make_bins: bool = True):\n",
    "        self.make_bins = make_bins\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_title(name: str) -> str:\n",
    "        if pd.isna(name):\n",
    "            return 'Unknown'\n",
    "        try:\n",
    "            part = name.split(',')[1]\n",
    "            title = part.split('.')[0].strip()\n",
    "            return title\n",
    "        except Exception:\n",
    "            return 'Unknown'\n",
    "\n",
    "    @staticmethod\n",
    "    def _ticket_prefix(ticket: str) -> str:\n",
    "        if pd.isna(ticket):\n",
    "            return 'MISSING'\n",
    "        # Keep only alpha tokens as prefix; else 'NONE'\n",
    "        toks = re.split(r'[\\s/]+', str(ticket))\n",
    "        toks = [t for t in toks if t and not t.isdigit()]\n",
    "        return toks[0].upper() if toks else 'NONE'\n",
    "\n",
    "    @staticmethod\n",
    "    def _deck_from_cabin(cabin: str) -> str:\n",
    "        if pd.isna(cabin) or str(cabin).strip() == '' or str(cabin).lower() == 'nan':\n",
    "            return 'U'  # Unknown\n",
    "        return str(cabin)[0].upper()\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        # Stateless (all stats learned later by downstream transformers)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = X.copy()\n",
    "\n",
    "        # Basic safe casts\n",
    "        for col in ['Age', 'Fare', 'SibSp', 'Parch', 'Pclass']:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "        # Title, Deck, TicketPrefix\n",
    "        df['Title'] = df['Name'].apply(self._extract_title) if 'Name' in df.columns else 'Unknown'\n",
    "        df['Deck'] = df['Cabin'].apply(self._deck_from_cabin) if 'Cabin' in df.columns else 'U'\n",
    "        df['TicketPrefix'] = df['Ticket'].apply(self._ticket_prefix) if 'Ticket' in df.columns else 'NONE'\n",
    "\n",
    "        # Family features\n",
    "        df['SibSp'] = df['SibSp'].fillna(0)\n",
    "        df['Parch'] = df['Parch'].fillna(0)\n",
    "        df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "        df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "\n",
    "        # Group size by ticket\n",
    "        if 'Ticket' in df.columns:\n",
    "            # Use groupby on the current batch (fold) only\n",
    "            df['GroupSizeByTicket'] = df.groupby('Ticket')['Ticket'].transform('count')\n",
    "        else:\n",
    "            df['GroupSizeByTicket'] = 1\n",
    "\n",
    "        # Fare per person (avoid division by zero)\n",
    "        df['FarePerPerson'] = df['Fare'] / df['FamilySize']\n",
    "        df['FarePerPerson'] = df['FarePerPerson'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "        # Optional coarse bins as categorical helpers\n",
    "        if self.make_bins:\n",
    "            df['AgeBin'] = pd.cut(df['Age'], bins=[0, 12, 18, 30, 45, 60, 80, np.inf], right=False, include_lowest=True).astype('category')\n",
    "            df['FareBin'] = pd.qcut(df['Fare'], q=5, duplicates='drop').astype('category')\n",
    "        else:\n",
    "            df['AgeBin'] = pd.Series(['NA'] * len(df), dtype='category')\n",
    "            df['FareBin'] = pd.Series(['NA'] * len(df), dtype='category')\n",
    "\n",
    "        # Simple interaction that uses numeric Age & Pclass; leave NaNs for imputer\n",
    "        if 'Age' in df.columns and 'Pclass' in df.columns:\n",
    "            df['AgeClass'] = df['Age'] * df['Pclass']\n",
    "        else:\n",
    "            df['AgeClass'] = np.nan\n",
    "\n",
    "        # Keep a curated set of columns for modeling\n",
    "        keep_cols = [\n",
    "            # Original numeric\n",
    "            'Pclass', 'Age', 'SibSp', 'Parch', 'Fare',\n",
    "            # Engineered numeric\n",
    "            'FamilySize', 'IsAlone', 'GroupSizeByTicket', 'FarePerPerson', 'AgeClass',\n",
    "            # Categorical\n",
    "            'Sex', 'Embarked', 'Title', 'Deck', 'TicketPrefix', 'AgeBin', 'FareBin'\n",
    "        ]\n",
    "        # Survive gracefully if some columns are missing in the raw data\n",
    "        keep_cols = [c for c in keep_cols if c in df.columns]\n",
    "\n",
    "        return df[keep_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f236745",
   "metadata": {},
   "source": [
    "## 3) Rare-Category Grouper (fit **inside** CV folds)\n",
    "Groups very infrequent categories to `Rare` based on training‑fold frequencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65548789",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RareCategoryGrouper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Group infrequent categories to 'Rare' per column.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    min_freq : float\n",
    "        Minimum relative frequency required to keep a category.\n",
    "    columns : List[str]\n",
    "        Categorical columns to apply grouping.\n",
    "    \"\"\"\n",
    "    def __init__(self, min_freq: float = 0.02, columns: Optional[List[str]] = None):\n",
    "        self.min_freq = min_freq\n",
    "        self.columns = columns\n",
    "        self.keep_maps_ = {}\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        self.keep_maps_ = {}\n",
    "        cols = self.columns if self.columns is not None else X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        for col in cols:\n",
    "            vc = X[col].astype('category').value_counts(normalize=True, dropna=False)\n",
    "            keep = set(vc[vc >= self.min_freq].index.astype(str).tolist())\n",
    "            self.keep_maps_[col] = keep\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X = X.copy()\n",
    "        for col, keep in self.keep_maps_.items():\n",
    "            if col in X.columns:\n",
    "                X[col] = X[col].astype(str).where(X[col].astype(str).isin(keep), other='Rare')\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d0d1d",
   "metadata": {},
   "source": [
    "## 4) ColumnTransformer: Imputation, Encoding, and Scaling\n",
    "- Numeric: `SimpleImputer(strategy='median')` then **scale for linear/knn/svm** models.\n",
    "- Categorical: `SimpleImputer('most_frequent')` and `OneHotEncoder(handle_unknown='ignore')`.\n",
    "    \n",
    "We will build two preprocessors:\n",
    "1. `preprocess_scaled` for models that need scaling (LogReg, LinearSVC/SGD, SVC-RBF, KNN, Perceptron)\n",
    "2. `preprocess_tree` for tree/forest/naive bayes (no scaling required; NB will accept dense output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8265e562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper to infer column types after FeatureBuilder\n",
    "def infer_columns(df: pd.DataFrame) -> Tuple[List[str], List[str]]:\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    return num_cols, cat_cols\n",
    "\n",
    "# Fit the feature builder once on the raw train_df to discover columns (doesn't learn stats)\n",
    "fb = FeatureBuilder(make_bins=True)\n",
    "feat_preview = fb.fit_transform(train_df)\n",
    "\n",
    "num_cols, cat_cols = infer_columns(feat_preview)\n",
    "\n",
    "rare_cols = [c for c in cat_cols if c in ['Title', 'Deck', 'TicketPrefix', 'AgeBin', 'FareBin']]\n",
    "\n",
    "# Pipelines use RareCategoryGrouper -> ColumnTransformer\n",
    "grouper = RareCategoryGrouper(min_freq=0.02, columns=rare_cols)\n",
    "\n",
    "# For models that need scaling\n",
    "numeric_scaled = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_common = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocess_scaled = Pipeline([\n",
    "    ('features', fb),\n",
    "    ('rare', grouper),\n",
    "    ('ct', ColumnTransformer([\n",
    "        ('num', numeric_scaled, num_cols),\n",
    "        ('cat', categorical_common, cat_cols)\n",
    "    ], remainder='drop', verbose_feature_names_out=False))\n",
    "])\n",
    "\n",
    "# For tree/naive bayes models (no scaling)\n",
    "numeric_tree = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "preprocess_tree = Pipeline([\n",
    "    ('features', fb),\n",
    "    ('rare', grouper),\n",
    "    ('ct', ColumnTransformer([\n",
    "        ('num', numeric_tree, num_cols),\n",
    "        ('cat', categorical_common, cat_cols)\n",
    "    ], remainder='drop', verbose_feature_names_out=False))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f6e95",
   "metadata": {},
   "source": [
    "## 5) Build Model Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a9a7528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Logistic Regression',\n",
       " 'Linear SVC',\n",
       " 'SGD (Log Loss)',\n",
       " 'Perceptron',\n",
       " 'SVC (RBF)',\n",
       " 'KNN (k=15)',\n",
       " 'Random Forest',\n",
       " 'Decision Tree',\n",
       " 'Gaussian NB']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def make_pipelines():\n",
    "    models = {}\n",
    "\n",
    "    # Linear / margin / distance-based -> scaled preprocessor\n",
    "    models['Logistic Regression'] = Pipeline([\n",
    "        ('prep', preprocess_scaled),\n",
    "        ('clf', LogisticRegression(max_iter=2000, random_state=RANDOM_STATE))\n",
    "    ])\n",
    "\n",
    "    models['Linear SVC'] = Pipeline([\n",
    "        ('prep', preprocess_scaled),\n",
    "        ('clf', LinearSVC(random_state=RANDOM_STATE))\n",
    "    ])\n",
    "\n",
    "    models['SGD (Log Loss)'] = Pipeline([\n",
    "        ('prep', preprocess_scaled),\n",
    "        ('clf', SGDClassifier(loss='log_loss', max_iter=2000, random_state=RANDOM_STATE))\n",
    "    ])\n",
    "\n",
    "    models['Perceptron'] = Pipeline([\n",
    "        ('prep', preprocess_scaled),\n",
    "        ('clf', Perceptron(max_iter=2000, random_state=RANDOM_STATE))\n",
    "    ])\n",
    "\n",
    "    models['SVC (RBF)'] = Pipeline([\n",
    "        ('prep', preprocess_scaled),\n",
    "        ('clf', SVC(kernel='rbf', C=1.0, gamma='scale', random_state=RANDOM_STATE))\n",
    "    ])\n",
    "\n",
    "    models['KNN (k=15)'] = Pipeline([\n",
    "        ('prep', preprocess_scaled),\n",
    "        ('clf', KNeighborsClassifier(n_neighbors=15))\n",
    "    ])\n",
    "\n",
    "    # Tree-based / NB -> unscaled preprocessor\n",
    "    models['Random Forest'] = Pipeline([\n",
    "        ('prep', preprocess_tree),\n",
    "        ('clf', RandomForestClassifier(\n",
    "            n_estimators=400, max_depth=None, min_samples_split=2,\n",
    "            min_samples_leaf=1, random_state=RANDOM_STATE, n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    models['Decision Tree'] = Pipeline([\n",
    "        ('prep', preprocess_tree),\n",
    "        ('clf', DecisionTreeClassifier(random_state=RANDOM_STATE))\n",
    "    ])\n",
    "\n",
    "    # GaussianNB expects dense; our OneHotEncoder uses sparse=False above\n",
    "    models['Gaussian NB'] = Pipeline([\n",
    "        ('prep', preprocess_tree),\n",
    "        ('clf', GaussianNB())\n",
    "    ])\n",
    "\n",
    "    return models\n",
    "\n",
    "models = make_pipelines()\n",
    "list(models.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7235bc5e",
   "metadata": {},
   "source": [
    "## 6) Cross‑Validated Evaluation (Stratified K‑Fold)\n",
    "- **n_splits=5**, shuffled with fixed seed for reproducibility\n",
    "- Metric: **accuracy**\n",
    "    \n",
    "We also keep the same folds across models for fairness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "447ec248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC (RBF)</td>\n",
       "      <td>0.828278</td>\n",
       "      <td>0.014953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.826044</td>\n",
       "      <td>0.011695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.824926</td>\n",
       "      <td>0.015922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.823765</td>\n",
       "      <td>0.018212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN (k=15)</td>\n",
       "      <td>0.801324</td>\n",
       "      <td>0.019533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD (Log Loss)</td>\n",
       "      <td>0.797960</td>\n",
       "      <td>0.014892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gaussian NB</td>\n",
       "      <td>0.787848</td>\n",
       "      <td>0.018901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.785619</td>\n",
       "      <td>0.033304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.728379</td>\n",
       "      <td>0.022818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Mean Accuracy       Std\n",
       "0            SVC (RBF)       0.828278  0.014953\n",
       "1           Linear SVC       0.826044  0.011695\n",
       "2  Logistic Regression       0.824926  0.015922\n",
       "3        Random Forest       0.823765  0.018212\n",
       "4           KNN (k=15)       0.801324  0.019533\n",
       "5       SGD (Log Loss)       0.797960  0.014892\n",
       "6          Gaussian NB       0.787848  0.018901\n",
       "7        Decision Tree       0.785619  0.033304\n",
       "8           Perceptron       0.728379  0.022818"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = train_df.drop(columns=['Survived']) if 'Survived' in train_df.columns else train_df.copy()\n",
    "y = train_df['Survived'].astype(int) if 'Survived' in train_df.columns else None\n",
    "assert y is not None, \"The training data must include a 'Survived' column.\"\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "rows = []\n",
    "for name, pipe in models.items():\n",
    "    scores = cross_val_score(pipe, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    rows.append({\n",
    "        'Model': name,\n",
    "        'Mean Accuracy': scores.mean(),\n",
    "        'Std': scores.std(),\n",
    "        'Fold Scores': scores\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(rows).sort_values(by='Mean Accuracy', ascending=False).reset_index(drop=True)\n",
    "results_df[['Model', 'Mean Accuracy', 'Std']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333597b4",
   "metadata": {},
   "source": [
    "## 7) Fit Best Model on Full Training Set (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "827d7dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: SVC (RBF)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_row = results_df.iloc[0]\n",
    "best_name = best_row['Model']\n",
    "best_model = models[best_name]\n",
    "best_model.fit(X, y)\n",
    "\n",
    "print(f\"Best model: {best_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96448b0e",
   "metadata": {},
   "source": [
    "## 8) Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5362951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cross-validated results to titanic_q2_cv_results.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "OUT_CSV = 'titanic_q2_cv_results.csv'\n",
    "results_df.to_csv(OUT_CSV, index=False)\n",
    "print(f\"Saved cross-validated results to {OUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea3f8f4",
   "metadata": {},
   "source": [
    "## 9) Notes for Your Report\n",
    "- The preprocessing avoids target leakage by learning imputers, rare-category grouping, and encoders **inside** CV folds.\n",
    "- We keep continuous features for margin-based models; bins are present for trees via one-hot.\n",
    "- Title, Deck, TicketPrefix, FamilySize, GroupSizeByTicket, FarePerPerson, and AgeClass generally add signal.\n",
    "- Report your **Mean ± Std accuracy** per model and briefly justify why this pipeline addresses Kaggle’s common pitfalls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29536a39",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e77c1ea8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
